---
layout: article
title: Fault-Diagnosis_CWRU_DL_1
mathjax: true
tags: Fault-Diagnosis

---

> **TOPIC:** 用CNN网络对轴承进行故障诊断
> 
> **Task:** 
> 
> * Data Processing
>   
>   - [x] m1: Convert signals to 2-D images   [Paper](https://ieeexplore.ieee.org/abstract/document/8114247)
>   
>   - [ ] m2: Wavelet transform of time-series data to generate spectrograms
> 
> * Model
>   
>   - [x] CNN
> 
> * Train & Inference
>   
>   - [x] Train
>   
>   - [x] Inference
> 
> * Cons & Future

# I Data preprocessing

本次使用CWRU轴承数据集在四种负载的DE位置上采样得到的数据，10种故障类型（normal+9），将数据载入，整合为list:

```python
normal = [normal_0, normal_1, normal_2, normal_3]
ball_18 = [ball_18_0, ball_18_1, ball_18_2, ball_18_3]
......
Data = [normal, ball_18, ball_36, ball_54, inner_18, inner_36,
        inner_54, outer_18, outer_36, outer_54,]
```

## 1.1 Convert signals to 2-D images

CWRU数据是时序数据，选取2D-CNN网络进行特征提取，如何将时序数据转为2D数据呢？这里提供两种解决思路：

1. **直接堆叠时序数据**（[A New Convolutional Neural Network-Based Data-Driven Fault Diagnosis Method](https://ieeexplore.ieee.org/abstract/document/8114247)）
   
   <img title="" src="https://raw.githubusercontent.com/lzboo/ImgStg/main/2022/06/01-16-03-42-1.png" alt="1.png" width="362" data-align="center">
   
   * 2D-CNN一般处理二维数据(图像)，将CWRU数据中的每个**采样点**视作图像中的一个**像素点**
   
   * 一个样本为64x64“图像”，即4096个采样点构成一个“图像”

```python
'''Convert signals to 2-D images'''

train = []
train_label = []
test = []
test_label = []

for d_type in range(10):                         # 10类 Data, 每一类下有4份独立数据(rpm)
    data = Data[d_type]                          # 取第(d_type)类, len(data)=4
    for rpm in range(4):
        data_load = data[rpm]                    # 选取其中一个speed
        max_start = len(data_load) - 4096        # 每4096(64*64)个采样点组成一个样本，最后一个样本的初始采样点为max_start
        starts = []

        # Train
        for i in range(700):
            # 随机采样，即随机选取一个start, 该start不在starts[]里,就加入
            while True:
                start = random.randint(0, max_start)
                if start not in starts:
                    starts.append(start)
                    break

            # 以start为始，顺取4096个采样点，堆叠为二维数据
            img = data_load[start : start + 4096]
            img = np.array(img)

            # 生成一个训练样本，对应生成一个label
            train.append(img.reshape(64, 64))   
            train_label.append(d_type)
            
        # Test
        for i in range(300):
            while True:
                start = random.randint(0, max_start)
                if start not in starts:
                    starts.append(start)
                    break

            img = data_load[start : start + 4096]
            img = np.array(img)
            test.append(img.reshape(64, 64))
            test_label.append(d_type)
    
print(len(train))
print("train:%d"%(len(train)))
print("train_label:%d"%(len(train_label)))
print("test:%d"%(len(test)))
print("test_label:%d"%(len(test_label)))

# 最终训练样本：28000 = 700*4*10   测试样本：12000 = 300*4*10
```

2. **选取阶段时序数据，经小波变换，生成频谱图**
   
   * 将时间T内的采样点经小波变换，生成频谱图作为网络输入
   
   * 一个频谱图作为一个样本

### 1.2.1 Dataset & DataLoader

```python
class MyData(Dataset):
    def __init__(self, pics, labels):
        self.pics = pics
        self.labels = labels

        # print(len(self.pics.files))
        # print(len(self.labels.files))

    def __getitem__(self, index):
        # print(index)
        # print(len(self.pics))
        assert index < len(self.pics)
        return torch.Tensor([self.pics[index]]), self.labels[index]

    def __len__(self):
        return len(self.pics)

    def get_tensors(self):
        return torch.Tensor([self.pics]), torch.Tensor(self.labels)
```

```python
trainset = MyData(train_pics, train_labels)
trainloader = torch.utils.data.DataLoader(
            trainset, batch_size=4, shuffle=True, num_workers=2
            )
for x, y in trainloader:
      print(x.shape)
      print(y.shape)

# torch.Size([4, 1, 64, 64])
# torch.Size([4])
```

# II Model

<img title="" src="https://raw.githubusercontent.com/lzboo/ImgStg/main/2022/06/01-16-46-26-2.png" alt="2.png" data-align="center" width="581">

```python
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(1, 32, 5, padding=2), # in_channels, out_channels, kernel_size
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # kernel_size, stride
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.fc = nn.Sequential(
            nn.Linear(256*4*4, 2560),
            nn.ReLU(),
            nn.Linear(2560, 1000),
            nn.ReLU(),
            nn.Linear(1000, 10)
        )

    def forward(self, img):
        feature = self.conv(img)
        output = self.fc(feature.view(img.shape[0], -1))
        return output
```

<img src="https://raw.githubusercontent.com/lzboo/ImgStg/main/2022/06/01-17-08-21-2.png" title="" alt="2.png" data-align="center">



# III Train & Inference

## 3.1 Train

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

net = Net().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr)

for epoch in range(num_epoch):
    run_loss = 0
    for i, data in enumerate(trainloader):
        img, label = data
        img = img.cuda()
        label = label.cuda()
        output = net(img)

        loss = criterion(output, label)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        run_loss += loss
        
        if i % 1000 == 999:
            print("epoch:", epoch, "[", i-999, ":", i, "]", "loss:", run_loss.item()/1000)
            run_loss = 0
        

    path  = "/content/drive/MyDrive/Colab_Notebooks/CWRU/cnn_net.pth"
    torch.save(net.state_dict(), path)
    print("save successfully!")
```

![3.png](https://raw.githubusercontent.com/lzboo/ImgStg/main/2022/06/01-16-50-08-3.png)

## 3.2 Inference

```python
path = "/content/drive/MyDrive/Colab_Notebooks/CWRU/cnn_net.pth"
net = Net().to(device)
net.load_state_dict(torch.load(path))
print("Load sucessfully!")

correct = 0
total = 0
with torch.no_grad():
    for img, label in testloader:
        img = img.cuda()
        label = label.cuda()
        output = net(img)
        _, pred = torch.max(output, 1)
        total += batch_size
        correct += (pred == label).sum().item()

print("correct:", float(correct / total) * 100, "%")
```

![1.png](https://raw.githubusercontent.com/lzboo/ImgStg/main/2022/06/01-17-06-41-1.png)



# IV Cons & Future

## 5.1 Cons & Que

初次看到**直接堆叠**方法，大为震撼，非常的简单粗暴，对该方法效果非常质疑。于是进行实验，发现效果竟比上次(辛苦特征提取+XGBoost)效果好很多，沉默了...

1. 该方法在**更大规模、噪音较多**数据集上还有效吗？（CWRU数据集为模拟采集，噪音较少）

2. CNN在这种 **“人造图像”** 上到底在提取什么样的特征？

3. 这种方法在**所有时序数据上都行之有效**吗？还是仅在**周期序列**上有效？
   
   推测作者使用这种处理时序数据取得成果的原因在：采样点是**周期序列**，卷积这种方式可以**整合不同周期的数据**（这种推测需要在一个非周期时序数据集上验证）

## 5.2 Future

- 上面的方法将CWRU数据集刷爆了，计划更换数据集:
  
  * 在非周期时序数据上使用**直接堆叠**，验证：该方法的有效性是否依赖**数据周期性**
  
  * 对比**直接堆叠**+**小波变换频谱图**两种方法，验证：效果好是否是数据集噪音小的问题

- 如果这两种方法在更大的数据集上表现不好，那就可以尝试一个新idea：**双流网络**——一个分支提取时域特征，一个分支提取频域特征


